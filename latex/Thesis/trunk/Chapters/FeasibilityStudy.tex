%!TEX TS-program = pdflatex
%!TEX encoding = UTF-8 Unicode

\chapter{Feasibility Study}
\label{chap:feas}
Entering a new field in computing without enough exeperience on the platform it 
is always advisable to get a better knowledge about the hardware ans software before
designing anything without proper knowledge. A feasibility study can give an overview
if a project is technically feasible and a way to gain some knowledge about the
complete eco system. Furthermore the study  can answer first questions and help
demistify myths. 

There are several myths about \gls{GPGPU} which will be examined and explained
Listed below some myths in no particular order.
\begin{enum}
	\item \Gls{GPU} programs are written with a graphics \gls{API} and layered on top 
		of graphics
	\label{enum:api}
	\item \Glspl{GPU} can only do a gather and no scatter memory access
	\label{enum:gather}
	\item \Glspl{GPU} are power-inefficient
	\label{enum:ineff}
	\item \Glspl{GPU} don't do real floating point math
	\label{enum:float}
	\item \Glspl{GPU} in average one can only exploit about 10\% of the peak 
		performance for general purpose computing
	\label{enum:exploit}
	\item \Glspl{GPU} are very wide \gls{SIMD} machines on which branching is 	  
		impossible, with 4-wide vector registers
 	\label{enum:simd}
\end{enum}

The most interesting myth here is that in average one can only exploit about
10\% of the peak performance for general purpose computing, which in turn would
lead to that \glspl{GPU} are power-inefficient in average. Another thing to keep
an eye on is the statement that \glspl{GPU} do not do real floating point math
which would exclude many communities ( \gls{HPC}, Physics, Astronomy, \ldots)
\graffito{Many \gls{HPC}, Physics, Astronomy,... benchmarks and algorithms rely
on floating point math} from spending time in doing \gls{GPGPU}.

Therefore the first step before choosing an algorithm or put further energy into
research of \glspl{GPU} is to make the feasibility study. The study will examine
the myths and show solutions to the problems respectively statements.
Furthermore it will show whether the technology, software eco system exists for
building applications on \glspl{GPU} and how difficult it will be to build.

By the means of a ray tracer the study will show which steps have to be 
undertaken to gain high performance with an parallel algorithm and show which 
architectural points have to be considered when designing an application.

\section{An Overview of Ray Tracing}
Ray tracing is a technique for realistic image synthesis. Ray tracing as the
name says traces light rays generated from an imaginary camera to their points
of origin. Ray tracing is based upon a physical, mathematical model behind
light, which facilitates to render photo realistic images. 

Ray tracing can be seen as an extension to ray casting. Therefore its easier to
understand ray tracing if the base concept of ray casting are understood. The
next section will introduce ray casting \footnote{For an in depth description of
ray tracing on a parallel machine see \citeauthor{citeulike:80546}
\citep{citeulike:80546}}.

\section{Ray Casting}
Ray casting was first introduced by \citeauthor{citeulike:841961}
\citep{citeulike:841961} he developed some techniques for a shading machine for
rendering of solids.

First of all it is important to understand the concept of rays. A ray is the
path of a particle of light (photon) extending from the eye into the
scene \citep{Glassner289}. The path is a thin, straight line used to model a beam
of light. Each ray can be seen as a \textit{feeler}\graffito{The ray scans or 
rasters the scene that is why a ray is often called a feeler} that reaches the 
scene and finds out which objects are visible and what color the object has at a 
specific point. Rays are the fundamental element of any ray tracer.

The representation of light on the screen is organized in so called pixels.
A pixel is a point sample not a little geometric square. This misconception
is widespread and it is an issue that strikes right at the root of correct
image computing and the ability to correctly integrate the discrete and the
continuous \citep{AlvyRaySmith95}.

The color of a given pixel is the color of the light that passes from the
object, through the associated pixel into the eye \citep{Hearn94}.

For each pixel on the screen a ray is cast from the eye through the pixel into
the virtual world. Then for each object it is checked if the ray intersects any
of them. If there are several objects in a scene intersected by the ray the
shortest distance to the intersection point is the one that is visible to the
eye. All other intersection are behind the nearest object and not visible
respectively occluded by the visible object. The color at that point is the
accumulated contribution of intensities radiated from all light sources. This
color is given to the pixel through which the ray passed. Ray casting does not
consider light reflected or transmitted by other objects in contrast to ray
tracing.

Ray casters and ray tracers spent most of their time calculating intersections
of rays with different objects. \citeauthor{citeulike:3770900}
\citep{citeulike:3770900} estimates that anywhere from 75\% to over 95\% of
rendering time is spent in intersection tests. For example an image with 640
pixel width and 480 pixels height, for a total of 307200 pixels, with a medium
complex scene with 100 objects results in 30720000 intersection tests. There are
well documented ray tracing accelerating techniques not only to decrease the
number of intersection tests per ray but also to decrease the number of rays.

In the study the standard ray casting algorithm will be used only, which means
that every ray will be intersected with every object to have a high arithmetic
density and not to be limited by the memory bandwidth.

Further experiments to extend the basic ray casting algorithm to ray tracing 
will be discarded this will only add more complexity to the algorithm and will
not help in solving the essential problems. 

\section{Performance tuning} % (fold)
\label{sec:performance_tuning}

After the initial port of the ray tracer to \gls{CUDA}, the first goal was to 
make it run on the \gls{GPU}, it was time to fine tune the run configuration. 
For any \gls{CUDA} application it is crucial to take a look at register, shared 
memory and local memory usage. The performance of the application  depends on
how good/bad the existing resources are exploited.

The examination of the ray traced showed that the initial port used 48
registers, 28 bytes shared memory and 96 byte constant memory per thread. As
shown in \textbf{REF. to \gls{CUDA} Application Stuff} the number of launched threads,
blocks and grids is dependent on the three factors mentioned above.

Each \gls{SM} has 8192 registers which means one could have 8192/48 = 170 threads
to fully exploit the resources 8 blocks should be launched so 170/8 = 21 threads
per block which is by far too low. It is easily spotted that the application is
limited by registers per \gls{SM}. These calculations can easily be done with the
\emph{CUDA occupancy calculator} supplied with the SDK.

After fiddling around with compiler switches especially the switch that limits
the used registers \emph{-maxrregcount=x}
the application used only 14 register which meant we could have a blocksize of
8, 8x8 = 64 threads per block \graffito{It is always good to have a thread count
which is a multiple of 32. A warp consits of 32 threads and the scheduler can
easier schedule the threads}. When reducing the amount of registers used, one
has to consider that registers which are additionally needed are allocated from
the local memory rather than the register file. Local memory is located in the
global memory which has a high latency (200--400 cycles) and registers often
referenced have a big impact on performance. The application can become memory
bound.

The \autoref{tab:runconfig} shows the run configuration used for the sample runs. 

\begin{table}[ht]
	\centering
	\pgfplotstabletypeset{Tables/run.configuration.data}
  	\caption[Run configuration]{Run configuration.}	
	\label{tab:runconfig}
\end{table}



To summarize, just by compiling the application and fiddling with the run
parameters one can achieve, in this case, a speedup of about 8 times. See
\autoref{tab:comp} for several runs varying object count and image size.

\begin{table}[ht]
	\centering
	\pgfplotstabletypeset{Tables/comp.cpu.gpu.data}
	\caption[Comparison between CPU and GPU]{Comparison between CPU and GPU.}
	\label{tab:comp}
\end{table}
	
	
As it can be seen in \autoref{tab:comp} the application runs 8 times faster but
when looking at the \glspl{GFLOP} values there are far beyond that what a
\gls{GPU} could achieve\footnote{The used \gls{GPU} is a G92 chip with peak 620
\glspl{GFLOP}}. The application is only using 0.5\% of the peak performance. All
performance values are gathered with the {\slcsmallcaps{NVIDIA}} Performance
Profiler availabe as well with the \gls{SDK}.

The reasons for this uneffective usage of processing power can be seen in
\autoref{tab:localmem} and \autoref{tab:globalmem}. The application is heavily
memory bound. The consequence of reducing the register usage is heavy access to
local memory, e.g. there are over 328000000 stores issued to the memory.
Furthermore the code is using many branches which is actually reflected by the
value 22578032.


\begin{table}[ht]
	\centering
	\pgfkeys{/pgf/number format/.cd,fixed,precision=2}
	\subfloat[Local memory]{
	\pgfplotstabletypeset{Tables/local.memory.data}
	\label{tab:localmem}}
	\qquad
	\subfloat[Branches]{
	\pgfplotstabletypeset{Tables/branches.data}
	\label{tab:branches}}
	
	\caption{Local memory and branches}
\end{table}

Another point is the access to global memory. The \gls{GPU} is able to do
coalesced reads and writes when possible otherwise the access is serialized. The
application was not ported with coalesced memory reads and writes in mind and
hence the application is loading almost everything incoherent. See
\autoref{tab:globalmem} for the values.

\begin{table}[ht]
    \centering
	\pgfkeys{/pgf/number format/.cd,fixed,precision=2}
	\pgfplotstabletypeset{Tables/global.memory.data}
  	\caption[Global memory loads and stores]{Global memory loads and stores.}
  	\label{tab:globalmem}
\end{table}

The ray tracer could be extended or optimized in many ways but it will be leaved
as is. The main point of the feasibility study was to get a feeling for
developing on \glspl{GPU} and to spot major drawbacks and obstacles. Keeping the
lessons learned here in mind the development of the main application will be
easier. The following section will demystify some but not all myths stated in
the beginning.
% section performance_tuning (end)

\section{Demystifing the Myths} % (fold)
\label{sec:demystifing_the_myths}
There were several myths about \gls{GPGPU} see \autoref{chap:feas} that are
simply wrong or need to be proven. Beginning with \autoref{enum:api} this
statement is simply wrong. Using \gls{CUDA} or the ATI \gls{SDK} \emph{Close To
Metal} no developer is anymore forced to use graphics \glspl{API}. Furthermore
the abandoned graphics \gls{API} for \glspl{GPGPU} makes it possible to gather
and scatter to the memory, which resolves myth \autoref{enum:gather}.

The \glspl{GPU} are able to do real floating point math. The myth
\autoref{enum:float} comes from a time where floats were only 16 or 24 bit and
had no support for \emph{NaN}, \emph{Rounding to zero} and so on. The situation
changed completely with the recent development and the switch to the
\emph{Unified Device Architecture} where \gls{SIMD} processing was discarded in
favour of more single independent threads.

The last to myths \autoref{enum:ineff} and \autoref{enum:exploit} are hard to
demystify. If one has a algorithm which fits excellently to the \gls{GPU} the
full power of the \gls{GPU} can be exploited and hence it is power efficient. It
depends heavily on the algorithm. The feasibility study has shown that one can
achieve easily a speedup but considering the inefficient use of the ressources
and the power dissipation it could be a slow down investing so much power for so
little return.

% section demystifing_the_myths (end)







