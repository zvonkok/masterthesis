\chapter{Feasibility Study}
\label{chap:feas}
There are several myths about \gls{GPGPU} which will be examined and solved 
with a feasibility study. Listed below some myths in no particular order.
\begin{enumerate}
	\item \gls{GPU} programs are written with a graphics api and layered on top 
		of graphics
	\label{enum:api}
	\item \glspl{GPU} can only do a gather and no scatter memory access
	\label{enum:gather}
	\item \glspl{GPU} are power-inefficient
	\label{enum:ineff}
	\item \glspl{GPU} don't do real floating point math
	\label{enum:float}
	\item \glspl{GPU} in average one can only exploit about 10\% of the peak 
		performance for general purpose computing
	\label{enum:exploit}
	\item \glspl{GPU} are very wide \gls{SIMD} machines on which branching is 	  
		impossible, with 4-wide vector registers
 	\label{enum:simd}
\end{enumerate}

The most interesting myth here is that in average one can only exploit about
10\% of the peak performance for general purpose computing, which in turn would 
lead to that \glspl{GPU} are power-inefficient in average. Another thing to 
keep an eye on is the statement that \glspl{GPU} do not do real floating point
math which would exclude many communities (\gls{HPC}, Physics, Astronomy, ..)
\graffito{Many \gls{HPC}, Physics, Astronomy,... benchmarks and algorithms rely 
on floating point math} from spending time in doing \gls{GPGPU}. 

Therefore the first step before choosing an algorithm or put further energy into
research of \glspl{GPU} is to make a feasibility study. The study will examine
the myths and show solutions to the problems respectively statements.
Furthermore it will show whether the technology, software eco system exists for
building applications on \glspl{GPU} and how difficult it will be to build.

By the means of a ray tracer the study will show which steps have to be 
undertaken to gain high performance with an parallel algorithm and show which 
architectural points have to be considered when designing an application.

\section{An Overview of Ray Tracing}
Ray tracing is a technique for realistic image synthesis. Ray tracing as the
name says traces light rays generated from an imaginary camera to their points
of origin. Ray tracing is based upon a physical, mathematical model behind
light, which facilitates to render photo realistic images. 

Ray tracing can be seen as an extension to ray casting. Therefore its easier to
understand ray tracing if the base concept of ray casting are understood. The
next section will introduce ray casting \footnote{For an in depth description of
ray tracing on a parallel machine see \citeauthor{citeulike:80546}
\citep{citeulike:80546}}.

\section{Ray Casting}
Ray casting was first introduced by \citeauthor{Appel68} \citep{Appel68} he
developed some techniques for a shading machine for rendering of solids.

First of all it is important to understand the concept of rays. A ray is the
path of a particle of light (photon) extending from the eye into the
scene \cite{Glassner289}. The path is a thin, straight line used to model a beam
of light. Each ray can be seen as a \textit{feeler}\graffito{The ray scans or 
rasters the scene that is why a ray is often called a feeler} that reaches the 
scene and finds out which objects are visible and what color the object has at a 
specific point. Rays are the fundamental element of any ray tracer.

The representation of light on the screen is organized in so called pixels.
A pixel is a point sample not a little geometric square. This misconception
is widespread and it is an issue that strikes right at the root of correct
image computing and the ability to correctly integrate the discrete and the
continuous \cite{AlvyRaySmith95}.

The color of a given pixel is the color of the light that passes from the
object, through the associated pixel into the eye \cite{Hearn94}.

For each pixel on the screen a ray is cast from the eye through the pixel into
the virtual world. Then for each object it is checked if the ray intersects any
of them. If there are several objects in a scene intersected by the ray the
shortest distance to the intersection point is the one that is visible to the
eye. All other intersection are behind the nearest object and not visible
respectively occluded by the visible object. The color at that point is the
accumulated contribution of intensities radiated from all light sources. This
color is given to the pixel through which the ray passed. Ray casting does not
consider light reflected or transmitted by other objects in contrast to ray
tracing.

Ray casters and ray tracers spent most of their time calculating intersections
of rays with different objects. \citeauthor{Whitted80} \citep{Whitted80} estimates
that anywhere from 75 percent to over 95 percent of rendering time is spent in
intersection tests. For example an image with 640 pixel width and 480 pixels
height, for a total of 307200 pixels, with a medium complex scene with 100
objects results in 30.720.000 intersection tests. There are well documented ray
tracing accelerating techniques not only to decrease the number of intersection
tests per ray but also to decrease the number of rays.

In the study the standard ray casting algorithm will be used only, which means
that every ray will be intersected with every object to have a high arithmetic
density and not to be limited by the memory bandwidth.

Further experiments to extend the basic ray casting algorithm to ray tracing 
will be discarded this will only add more complexity to the algorithm and will
not help in solving the essential problems. 

\section{Performance tuning} % (fold)
\label{sec:performance_tuning}

After the initial port of the ray tracer to \gls{CUDA}, the first goal was to 
make it run on the \gls{GPU}, it was time to fine tune the run configuration. 
For any \gls{CUDA} application it is crucial to take a look at register, shared 
memory and local memory usage. The performance of the application is depend on
how good/bad the existing resources are exploited.

The examination of the ray traced showed that the initial port used 48
registers, 28 bytes shared memory and 96 byte constant memory per thread. As
shown in \textbf{REF. to CUDA Application Stuff} the number of launched threads,
blocks and grids is dependent on the three factors mentioned above.

Each \gls{SM} has 8192 registers which means we could have 8192/48 = 170 threads
to fully exploit the resources 8 blocks should be launched so 170/8 = 21 threads per block which is by far too low. It is easily spotted that the application is
limited by registers / \gls{SM}. These calculations can easily be done with the \emph{CUDA occupancy calculator} supplied with the SDK. 

After fiddling around with compiler switches especially \emph{-maxrregcount=x}
the application used only 14 register which meant we could have a blocksize of
8, 8x8 = 64 threads per block \graffito{It is always good to have a thread count
which is a multiple of 32. A warp consits of 32 threads and the scheduler can
easier schedule the threads}. When reducing the amount of registers used, one
has to consider that registers which are additionally needed are allocated from
the local memory rather than the register file. Local memory is located in the
global memory which has a high latency (200-400 cycles) and registers often
referenced have a big impact on performance. The application can become memory
bound.

The Table \autoref{tab:runconfig} shows the run configuration used for the sample runs. 

\begin{table}[ht]
    \myfloatalign
  \begin{tabularx}{\textwidth}{ccccc} \toprule
	\multicolumn{5}{c}{\slcsmallcaps{Run Configuration}} \\ \midrule
	blockSize.x & blockSize.y & gridSize.x & gridSize.y & Regs. per Thread\\ 
  	8 & 8 & 96 & 96 & 14\\
    \bottomrule
  \end{tabularx}
  \caption[Run configuration]{Run configuration.}
  \label{tab:runconfig}
\end{table}

To summarize just by compiling the application and fiddling with the run
parameters one can achieve, in this case, a speedup of about 8 times. See Table
\autoref{tab:comp} for several runs varying object count and image size.

\begin{table}[ht]
   \myfloatalign
  \begin{tabularx}{\textwidth}{ccccc} \toprule
    \tableheadline{Image} & 
	\tableheadline{Objects} & 
	\tableheadline{CPU Gflops} &
	\tableheadline{GPU Gflops} &
	\tableheadline{Speedup}\\ \midrule
    768 & 338 &  0.37 & 3.17 & 8.54 \\
 	768 & 450 &  0.37 & 3.22 & 8.6\\
 	768 & 840 &  0.37 & 3.23 & 8.74\\ 
 	512 & 338 &  0.37 & 3.19 & 8.53\\
 	512 & 450 &  0.37 & 3.18 & 8.5\\
 	512 & 840 &  0.37 & 3.18 & 8.64\\ 
 	256 & 338 &  0.37 & 3.03 & 8.09\\
 	256 & 450 &  0.37 & 3.03 & 8.44\\
 	256 & 840 &  0.37 & 2.95 & 7.96\\
    \bottomrule
  \end{tabularx}
  \caption[Comparison between CPU and GPU]{Comparison between CPU and GPU.}
  \label{tab:comp}
\end{table}

As it can be seen in Table \autoref{tab:comp} the application runs 8 times faster but when looking at the \glspl{GFLOP} values there are far beyond that what a \gls{GPU} could achieve\footnote{The used \gls{GPU} is a G90 chip with peak 620 \glspl{GFLOP}}. The application is only using 0.5\% of the peak performance!\graffito{All performance values are gathered with the NVIDIA Performance Profiler availabe as well with the \gls{SDK}}  


The reasons for this uneffective usage of processing power can be seen in Table \autoref{tab:localmem} and Table \autoref{tab:globalmem}. The application is heavily memory bound. The consequence of reducing the register usage is heavy access to local memory, e.g. there are over 328000000 stores issued to the memory. Furthermore the code is using many branches which actually reflected by the value 22578032. 

\begin{table}[ht]
    \myfloatalign
  \begin{tabularx}{\textwidth}{cccc} \toprule
	\multicolumn{2}{c}{\slcsmallcaps{Local Memory}} &
	\multicolumn{2}{c}{\slcsmallcaps{Branches}} \\ \midrule
    Load & Store & Sum & Divergent\\
	63294179 & 328180560 & 22578032 & 26834\\
    \bottomrule
  \end{tabularx}
  \caption[Local memory and branches]{Local memory and branches.}
  \label{tab:localmem}
\end{table}

Another point is the access to global memory. The \gls{GPU} is able to do coalesced reads and writes when possible otherwise the access is serialized. 
The application was not ported with coalesced memory reads and writes in mind and hence the application is loading almost everything incoherent. See Table \autoref{tab:globalmem} for the values. 

\begin{table}[ht]
    \myfloatalign
  \begin{tabularx}{\textwidth}{cccc} \toprule
	\multicolumn{4}{c}{\slcsmallcaps{Global Memory}} \\ \midrule
    Load Incoherent & Load Coherent & Store Incoherent & Store Coherent \\
	1115657863 & 67961 & 2506752 & 0 \\
    \bottomrule
  \end{tabularx}
  \caption[Global memory loads and stores]{Global memory loads and stores.}
  \label{tab:globalmem}
\end{table}

The ray tracer could be extended or optimized in many ways but it will be leaved as is. The main point of the feasibility study was to get a \emph{feeling} for developing on \glspl{GPU} and to spot major drawbacks and obstacles. Keeping the lessons learned here in mind the development of the main application will be easier. The following section will demystify some but not all myths stated in the beginning.
% section performance_tuning (end)

\section{Demystifing the Myths} % (fold)
\label{sec:demystifing_the_myths}
There were several myths about \gls{GPGPU} see \autoref{chap:feas} that are simply wrong or need to be proven. Beginning with \autoref{enum:api} this statement is 
simply wrong. Using \gls{CUDA} or the ATI \gls{SDK} \emph{Close To Metal}
no developer is anymore forced to use graphics \glspl{API}. Furthermore the abandoned graphics \gls{API} for \glspl{GPGPU} makes it possible to gather and scatter to the memory, which resolves myth \autoref{enum:gather}. 

The \glspl{GPU} are able to do real floating point math. The myth \autoref{enum:float} comes from a time where floats were only 16 or 24 bit and had no support for \emph{NaN}, \emph{Rounding to zero} and so on. The situation changed completely with the recent development and the switch to the \emph{Unified Device Architecture} where \gls{SIMD} processing was discarded in 
favour of more single independent threads. 

The last to myths \autoref{enum:ineff} and \autoref{enum:exploit} are hard to demystify.
If one has a algorithm which fits excellently to the \gls{GPU} the full power of
the \gls{GPU} can be exploited and hence it is power efficient. It depends
heavily on the algorithm. The feasibility study has shown that one can achieve
easily a speedup but considering the inefficient use of the ressources and the
power dissipation it could be a slow down investing so much power for so little
return.

% section demystifing_the_myths (end)







