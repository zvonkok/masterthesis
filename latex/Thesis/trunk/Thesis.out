\BOOKMARK [1][-]{acknowledgments.1}{Acknowledgments}{}% 1
\BOOKMARK [0][]{chapter.1}{1 Introduction}{}% 2
\BOOKMARK [0][]{chapter.2}{2 Literature Review}{}% 3
\BOOKMARK [1][-]{section.2.1}{2.1 General Purpose Computing on Graphics Hardware}{chapter.2}% 4
\BOOKMARK [1][-]{section.2.2}{2.2 Parallel Programming \046 Thinking}{chapter.2}% 5
\BOOKMARK [1][-]{section.2.3}{2.3 Embarrassingly Parallel Algorithms}{chapter.2}% 6
\BOOKMARK [2][-]{subsection.2.3.1}{2.3.1 Computations which Map Well to GPUs}{section.2.3}% 7
\BOOKMARK [2][-]{subsection.2.3.2}{2.3.2 Ray Tracing}{section.2.3}% 8
\BOOKMARK [2][-]{subsection.2.3.3}{2.3.3 Photon Mapping}{section.2.3}% 9
\BOOKMARK [2][-]{subsection.2.3.4}{2.3.4 Multiple Precision Arithmetic}{section.2.3}% 10
\BOOKMARK [2][-]{subsection.2.3.5}{2.3.5 High Dynamic Range}{section.2.3}% 11
\BOOKMARK [2][-]{subsection.2.3.6}{2.3.6 Genetic Algorithms}{section.2.3}% 12
\BOOKMARK [2][-]{subsection.2.3.7}{2.3.7 Chaos Theory}{section.2.3}% 13
\BOOKMARK [2][-]{subsection.2.3.8}{2.3.8 Image Processing}{section.2.3}% 14
\BOOKMARK [1][-]{section.2.4}{2.4 Summary \046 Conclusion}{chapter.2}% 15
\BOOKMARK [0][]{chapter.3}{3 Parallel Processing with GPUs}{}% 16
\BOOKMARK [1][-]{section.3.1}{3.1 Parallel Architectures}{chapter.3}% 17
\BOOKMARK [1][-]{section.3.2}{3.2 The Tesla Architecture}{chapter.3}% 18
\BOOKMARK [1][-]{section.3.3}{3.3 Common Unified Device Architecture \(CUDA\)}{chapter.3}% 19
\BOOKMARK [1][-]{section.3.4}{3.4 CUDA Programming Model}{chapter.3}% 20
\BOOKMARK [1][-]{section.3.5}{3.5 A Simple Example}{chapter.3}% 21
\BOOKMARK [1][-]{section.3.6}{3.6 Porting Strategy for GPUs}{chapter.3}% 22
\BOOKMARK [0][]{chapter.4}{4 Feasibility Study}{}% 23
\BOOKMARK [1][-]{section.4.1}{4.1 An Overview of Ray Tracing}{chapter.4}% 24
\BOOKMARK [1][-]{section.4.2}{4.2 Ray Casting}{chapter.4}% 25
\BOOKMARK [1][-]{section.4.3}{4.3 Performance tuning}{chapter.4}% 26
\BOOKMARK [1][-]{section.4.4}{4.4 Demystifing the Myths}{chapter.4}% 27
\BOOKMARK [0][]{chapter.5}{5 Mean Shift}{}% 28
\BOOKMARK [1][-]{section.5.1}{5.1 Density Estimation}{chapter.5}% 29
\BOOKMARK [1][-]{section.5.2}{5.2 Kernel Density Estimation}{chapter.5}% 30
\BOOKMARK [1][-]{section.5.3}{5.3 Kernel and their Properties}{chapter.5}% 31
\BOOKMARK [1][-]{section.5.4}{5.4 Mean Shift}{chapter.5}% 32
\BOOKMARK [2][-]{subsection.5.4.1}{5.4.1 Density Gradient Estimation}{section.5.4}% 33
\BOOKMARK [2][-]{subsection.5.4.2}{5.4.2 Mean Shift Method}{section.5.4}% 34
\BOOKMARK [1][-]{section.5.5}{5.5 Filtering \046 Segmentation}{chapter.5}% 35
\BOOKMARK [2][-]{subsection.5.5.1}{5.5.1 Mean Shift Filtering}{section.5.5}% 36
\BOOKMARK [2][-]{subsection.5.5.2}{5.5.2 Mean Shift Segmentation}{section.5.5}% 37
\BOOKMARK [0][]{chapter.6}{6 Mean Shift Algorithm Analysis}{}% 38
\BOOKMARK [1][-]{section.6.1}{6.1 Profiling the Original Code}{chapter.6}% 39
\BOOKMARK [1][-]{section.6.2}{6.2 Amdahl's law}{chapter.6}% 40
\BOOKMARK [1][-]{section.6.3}{6.3 Data \046 Task Parallelism}{chapter.6}% 41
\BOOKMARK [2][-]{subsection.6.3.1}{6.3.1 Task Parallelism}{section.6.3}% 42
\BOOKMARK [2][-]{subsection.6.3.2}{6.3.2 Data Parallelism}{section.6.3}% 43
\BOOKMARK [1][-]{section.6.4}{6.4 Data Flow}{chapter.6}% 44
\BOOKMARK [1][-]{section.6.5}{6.5 Summary}{chapter.6}% 45
\BOOKMARK [0][]{chapter.7}{7 Mean Shift Algorithm Design}{}% 46
\BOOKMARK [1][-]{section.7.1}{7.1 Programming Model}{chapter.7}% 47
\BOOKMARK [1][-]{section.7.2}{7.2 Thread Batching}{chapter.7}% 48
\BOOKMARK [1][-]{section.7.3}{7.3 Device Memory space}{chapter.7}% 49
\BOOKMARK [1][-]{section.7.4}{7.4 Warps}{chapter.7}% 50
\BOOKMARK [1][-]{section.7.5}{7.5 Program Flow}{chapter.7}% 51
\BOOKMARK [1][-]{section.7.6}{7.6 Summary}{chapter.7}% 52
\BOOKMARK [0][]{chapter.8}{8 Optimization Strategies}{}% 53
\BOOKMARK [1][-]{section.8.1}{8.1 Test \046 Benchmark Configuration}{chapter.8}% 54
\BOOKMARK [1][-]{section.8.2}{8.2 Offload Compute Intensive Parts}{chapter.8}% 55
\BOOKMARK [1][-]{section.8.3}{8.3 Global Memory \046 Coalescing}{chapter.8}% 56
\BOOKMARK [1][-]{section.8.4}{8.4 Division Instruction Optimization}{chapter.8}% 57
\BOOKMARK [1][-]{section.8.5}{8.5 Execution Configurations}{chapter.8}% 58
\BOOKMARK [1][-]{section.8.6}{8.6 Native Data Types}{chapter.8}% 59
\BOOKMARK [1][-]{section.8.7}{8.7 Avoid Branch Divergence}{chapter.8}% 60
\BOOKMARK [1][-]{section.8.8}{8.8 Shared Memory}{chapter.8}% 61
\BOOKMARK [1][-]{section.8.9}{8.9 Know the Algorithm}{chapter.8}% 62
\BOOKMARK [2][-]{section*.16}{Attractor}{section.8.9}% 63
\BOOKMARK [1][-]{section.8.10}{8.10 Unrolling Loops and Multiplications}{chapter.8}% 64
\BOOKMARK [1][-]{section.8.11}{8.11 Summary}{chapter.8}% 65
\BOOKMARK [0][]{chapter.9}{9 Performance \046 Scalability}{}% 66
\BOOKMARK [1][-]{section.9.1}{9.1 Varying the Image Size}{chapter.9}% 67
\BOOKMARK [2][-]{subsection.9.1.1}{9.1.1 Linearity}{section.9.1}% 68
\BOOKMARK [1][-]{section.9.2}{9.2 Multiple gpus}{chapter.9}% 69
\BOOKMARK [1][-]{section.9.3}{9.3 Overclocking the gpu}{chapter.9}% 70
\BOOKMARK [2][-]{subsection.9.3.1}{9.3.1 Increasing the Memory Clock}{section.9.3}% 71
\BOOKMARK [2][-]{subsection.9.3.2}{9.3.2 Increasing the Core Clock}{section.9.3}% 72
\BOOKMARK [3][-]{figure.caption.26}{Multiple gpus overclocked}{subsection.9.3.2}% 73
\BOOKMARK [1][-]{section.9.4}{9.4 Final Speedup}{chapter.9}% 74
\BOOKMARK [0][]{chapter.10}{10 Conclusions \046 Future Work}{}% 75
\BOOKMARK [0][]{section*.28}{Glossary}{}% 76
\BOOKMARK [0][]{section*.30}{Acronyms}{}% 77
\BOOKMARK [1][-]{lof.1}{List of Figures}{section*.30}% 78
\BOOKMARK [1][-]{lot.1}{List of Tables}{section*.30}% 79
\BOOKMARK [1][-]{lol.1}{List of Listings}{section*.30}% 80
\BOOKMARK [0][]{chapter*.35}{Bibliography}{}% 81
\BOOKMARK [0][]{appendix.A}{A Reference Tables}{}% 82
\BOOKMARK [0][]{appendix.B}{B Host \046 Kernel Source Code }{}% 83
